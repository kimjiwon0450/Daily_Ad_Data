import os
import json
from google.cloud import bigquery
from facebook_business.api import FacebookAdsApi
from facebook_business.adobjects.adaccount import AdAccount
import pandas as pd
import pandas_gbq
from datetime import datetime, timedelta
import time
from google.oauth2 import service_account
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# ===========================================================
# ì„¤ì • íŒŒì¼ ë¡œë“œ
# ===========================================================

try:
    with open('config.json', 'r', encoding='utf-8') as f:
        CONFIG = json.load(f)
except FileNotFoundError:
    print("âŒ 'config.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    exit()

# ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •ê°’ í• ë‹¹
KEY_PATH = CONFIG['google_key_file'] # êµ¬ê¸€ í‚¤ íŒŒì¼ëª…
PROJECT_ID = CONFIG['google_project_id'] # êµ¬ê¸€ í”„ë¡œì íŠ¸ ID
DATASET_ID = CONFIG['bigquery_dataset'] # ë¹…ì¿¼ë¦¬ ë°ì´í„°ì…‹ ì´ë¦„
SHEET_URL = CONFIG['google_sheet_url'] # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì£¼ì†Œ

# -----------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ê²°ê³¼ ë§¤í•‘, í† í° ê°€ì ¸ì˜¤ê¸°)
# -----------------------------------------------------------
def get_token(account_name):
    """ê³„ì • ì´ë¦„ì— ë”°ë¼ ì˜¬ë°”ë¥¸ í† í°ì„ ë°˜í™˜"""
    if account_name == "Leshine_beauty":
        return CONFIG['meta_access_token2'] # ë¥´ìƒ¤ì¸ ì „ìš©
    return CONFIG['meta_access_token1']     # ë‚˜ë¨¸ì§€ ê³µìš©

def get_result_info(action_list):
    if not isinstance(action_list, list):
        return 0.0, ""

    # ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ê²€ì‚¬
    target_map = {
        'lead': 'Meta ì ì¬ ê³ ê°',                  
        'complete_registration': 'ì›¹ì‚¬ì´íŠ¸ ë“±ë¡ ì™„ë£Œ', 
        'purchase': 'êµ¬ë§¤',                       
        'contact': 'ë¬¸ì˜',                        
        'schedule': 'ì˜ˆì•½',                       
        'submit_application': 'ì‹ ì²­ ì œì¶œ',          
        'start_trial': 'ì²´í—˜ ì‹œì‘',                 
        'link_click': 'ë§í¬ í´ë¦­'                  
    }

    action_dict = {}
    for item in action_list:
        atype = item.get('action_type')
        val = float(item.get('value', 0))
        action_dict[atype] = val

    for key, label in target_map.items():
        if key in action_dict:
            return action_dict[key], label
            
    return 0.0, ""

# -----------------------------------------------------------
# [ê³µí†µ] ë°ì´í„° ê°€ê³µ ë° ì—…ë¡œë“œ í•¨ìˆ˜
# -----------------------------------------------------------
def process_and_upload(data_list, table_name, option):
    # data_listê°€ Cursor ê°ì²´ì¼ ìˆ˜ë„ ìˆê³  ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìŒ
    all_data = [x for x in data_list] if not isinstance(data_list, list) else data_list
    
    if not all_data:
        print("âš ï¸ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = pd.DataFrame(all_data)

    rename_map = {'date_start': 'report_date', 'impressions': 'exposures'}
    df = df.rename(columns=rename_map)
    
    # actions ì²˜ë¦¬
    if 'actions' in df.columns:
        result_series = df['actions'].apply(get_result_info)
        df['leads'] = [x[0] for x in result_series]       
        df['result_type'] = [x[1] for x in result_series] 
    else:
        df['leads'] = 0
        df['result_type'] = ""

    # ìˆ«ì ë³€í™˜
    numeric_cols = ['spend', 'exposures', 'clicks', 'leads']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

            # ë¹…ì¿¼ë¦¬ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ëª…ì‹œì ìœ¼ë¡œ íƒ€ì… ë³€ê²½
            if col == 'spend':
                df[col] = df[col].astype(float) # ê´‘ê³ ë¹„ëŠ” ì†Œìˆ˜ì ì¼ ìˆ˜ ìˆìŒ
            else:
                df[col] = df[col].astype(int)   # í´ë¦­, ë…¸ì¶œ, ê²°ê³¼ìˆ˜ëŠ” ì •ìˆ˜

    # ë¬¸ì ë°ì´í„° (string) ê°•ì œ ë³€í™˜
    string_cols = ['campaign_name', 'ad_name', 'ad_id', 'result_type']
    for col in string_cols:
        if col in df.columns:
            df[col] = df[col].astype(str)

    # â˜… í•„í„°: ì§€ì¶œ, ê²°ê³¼, í´ë¦­ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì €ì¥
    df = df[ (df['leads'] > 0) | (df['spend'] > 0) | (df['clicks'] > 0) ]
    
    if df.empty:
        print("âš ï¸ í•„í„°ë§ í›„ ë‚¨ì€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df['collected_at'] = datetime.now() 
    df['channel'] = 'meta'

    bq_columns = [
        'campaign_name', 'ad_name', 'ad_id',
        'exposures', 'clicks', 'leads', 'result_type', 'spend', 
        'report_date', 'collected_at', 'channel'
    ]
    
    final_df = df[[c for c in bq_columns if c in df.columns]].copy()
    final_df['report_date'] = pd.to_datetime(final_df['report_date']).dt.date
    print(final_df)

    insert_bigquery(final_df, table_name, option)


def link_meta_yearly(account_info, start_str, end_str):
    ad_account_id = account_info['id']      # configì—ì„œ ê°€ì ¸ì˜¨ ê³„ì • ID
    table_name = account_info['bq_table_name'] # configì—ì„œ ê°€ì ¸ì˜¨ í…Œì´ë¸”ëª…
    hospital_name = CONFIG['hospital_name']
    my_access_token = get_token(account_info['name'])

    # 1. í˜ì´ìŠ¤ë¶ ì—°ê²°
    try:
        FacebookAdsApi.init(access_token=my_access_token)
    except Exception as e:
        print("âŒ í˜ì´ìŠ¤ë¶ í† í° ì¸ì¦ ì‹¤íŒ¨:", e)
        return
    
    # ë‚ ì§œ ë³€í™˜
    start_date = datetime.strptime(start_str, '%Y%m%d')
    end_date = datetime.strptime(end_str, '%Y%m%d')
    
    fields = ['campaign_name', 'ad_name', 'ad_id', 'spend', 'impressions', 'clicks', 'actions']

    # ê²°ê³¼ë¥¼ ë‹´ì„ ë¹ˆ ë¦¬ìŠ¤íŠ¸
    total_data_list = []
    current_start = start_date
    print(f"ğŸ“… ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")

    # 20ì¼ì”© ëŠì–´ì„œ ë£¨í”„
    while current_start < end_date:
        current_end = current_start + timedelta(days=20) 
        if current_end > end_date:
            current_end = end_date

        s_str = current_start.strftime('%Y-%m-%d')
        e_str = current_end.strftime('%Y-%m-%d')

        params = {
            'level': 'ad',
            'limit': '1000',
            'time_range': {'since': s_str, 'until': e_str},
            'time_increment': '1' 
        }

        try:
            print(f"â³ ìš”ì²­ ì¤‘... ({s_str} ~ {e_str})")
            data_cursor = AdAccount(ad_account_id).get_insights(fields=fields, params=params)
            chunk_data = [x for x in data_cursor]
            total_data_list.extend(chunk_data) # ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸°
            
            print(f"   -> {len(chunk_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ.")
            time.sleep(0.5)

        except Exception as e:
            print(f"âŒ {s_str}~{e_str} êµ¬ê°„ ì—ëŸ¬ ë°œìƒ: {e}")

        # ë‹¤ìŒ êµ¬ê°„ ì‹œì‘ì¼ = ì´ë²ˆ êµ¬ê°„ ì¢…ë£Œì¼ + 1ì¼
        current_start = current_end + timedelta(days=1)

    # -----------------------------------------------------------
    # ë°ì´í„° í†µí•© ë° ì²˜ë¦¬
    # -----------------------------------------------------------
    if total_data_list:
        print(f"   âœ… ì´ {len(total_data_list)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ. ì²˜ë¦¬ ì‹œì‘...")
        # ì—¬ê¸°ì„œ insert_bigqueryì˜ ì˜µì…˜ì€ ìƒí™©ì— ë”°ë¼ 'replace' ë˜ëŠ” 'append'
        # ë³´í†µ ê³¼ê±° ë°ì´í„° ì¬ì ì¬ëŠ” 'append' í›„ ì¤‘ë³µì œê±°ë¥¼ ëŒë¦¬ëŠ” ê²Œ ì•ˆì „í•©ë‹ˆë‹¤.
        process_and_upload(total_data_list, table_name, 'append')
    else:
        print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")    
 

def link_meta_daily(account_info):
    ad_account_id = account_info['id']      # configì—ì„œ ê°€ì ¸ì˜¨ ê³„ì • ID
    table_name = account_info['bq_table_name'] # configì—ì„œ ê°€ì ¸ì˜¨ í…Œì´ë¸”ëª…
    hospital_name = CONFIG['hospital_name']
    my_access_token = get_token(account_info['name'])

    # 1. í˜ì´ìŠ¤ë¶ ì—°ê²°
    try:
        FacebookAdsApi.init(access_token=my_access_token)
    except Exception as e:
        print("âŒ í˜ì´ìŠ¤ë¶ í† í° ì¸ì¦ ì‹¤íŒ¨:", e)
        return
    
    fields = ['campaign_name', 'ad_name', 'ad_id', 'spend', 'impressions', 'clicks', 'actions']

    params = {
        # 'level': 'campaign',      # ìº í˜ì¸ -> í´ë” 
        'level': 'ad',              # ê´‘ê³  -> íŒŒì¼
        'date_preset': 'yesterday',
        'limit': '500', # í•œ ë²ˆì— 500ê°œì”© ìš”ì²­
    }

    # try:
    print("â³ ë°ì´í„° ìš”ì²­ ì¤‘...")
    data_cursor = AdAccount(ad_account_id).get_insights(fields=fields, params=params)
    process_and_upload(data_cursor, table_name, 'append')

    # except Exception as e:
    #     print("âŒ ì—°ë™ ì‹¤íŒ¨:", e)


def insert_bigquery(final_df, table_name, option):
    # -----------------------------------------------------------
    # 6. BigQueryë¡œ ì „ì†¡ (ì—…ë¡œë“œ)
    # -----------------------------------------------------------
    destination_table = f"{DATASET_ID}.{table_name}"

    # try:
    # Configì— ìˆëŠ” í‚¤ íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
    credentials = service_account.Credentials.from_service_account_file(KEY_PATH)
    pandas_gbq.to_gbq(
        final_df, destination_table, project_id=PROJECT_ID,
        if_exists=option, credentials=credentials
    )
    print("ğŸ‰ BigQuery ì €ì¥ ì™„ë£Œ.")
    # except Exception as e:
    #     print("âŒ ì—…ë¡œë“œ ì‹¤íŒ¨:", e)

# -----------------------------------------------------------
# ì¤‘ë³µ ì œê±° í•¨ìˆ˜ (Config ì‚¬ìš©)
# -----------------------------------------------------------
def remove_duplicates(table_name):
    
    try:
        credentials = service_account.Credentials.from_service_account_file(KEY_PATH)
        client = bigquery.Client(credentials=credentials, project=PROJECT_ID)
        table_id = f"{PROJECT_ID}.{DATASET_ID}.{table_name}"
        print(f"ğŸ§¹ [{table_name}] ì¤‘ë³µ ë°ì´í„° ì²­ì†Œ ì‹œì‘...")

        # â˜… í•µì‹¬ SQL: ì¤‘ë³µëœ í–‰ ì¤‘ 'collected_at'ì´ ê°€ì¥ ìµœì‹ ì¸ ê²ƒë§Œ ë‚¨ê¸°ê³  ë®ì–´ì“°ê¸°
        query = f"""
                CREATE OR REPLACE TABLE `{table_id}`
                PARTITION BY report_date
                CLUSTER BY campaign_name
                AS
                SELECT * EXCEPT(rn)
                FROM (
                    SELECT *,
                        ROW_NUMBER() OVER (
                            PARTITION BY report_date, campaign_name, ad_name, ad_id, channel
                            ORDER BY collected_at DESC
                        ) as rn
                    FROM `{table_id}`
                )
                WHERE rn = 1
                """
        
        query_job = client.query(query)  # ì¿¼ë¦¬ ì‹¤í–‰
        query_job.result()  # ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        print(f"âœ¨ [BigQuery] {table_name} ì¤‘ë³µ ì œê±° ì™„ë£Œ.")

    except Exception as e:
        print("âŒ ì¤‘ë³µ ì œê±° ì‹¤íŒ¨:", e)

# -----------------------------------------------------------
# ì‹œíŠ¸ ë™ê¸°í™” í•¨ìˆ˜ (Config ì‚¬ìš©)
# -----------------------------------------------------------
def sync_bq_to_sheet(table_name):
    # í…Œì´ë¸” ì´ë¦„ì— ë”°ë¼ ì‹œíŠ¸ íƒ­ ì´ë¦„ ìë™ ê²°ì •
    """
    êµ¬ê¸€ ì‹œíŠ¸ì˜ ë§ˆì§€ë§‰ ë‚ ì§œë¥¼ í™•ì¸í•˜ê³ , ê·¸ ì´í›„ì˜ ë°ì´í„°ë¥¼ ë¹…ì¿¼ë¦¬ì—ì„œ ê°€ì ¸ì™€ ì¶”ê°€í•©ë‹ˆë‹¤.
    """

    if 'beauty' in table_name:
        sheet_name = "Bë©”íƒ€"
        category_name = "ë·°í‹°"
    elif 'foot' in table_name:
        sheet_name = "Fë©”íƒ€"
        category_name = "í’‹"
    elif 'dosu' in table_name:
        sheet_name = "Dë©”íƒ€"
        category_name = "ë„ìˆ˜"
    else:
        return
    
    # -------------------------------------------------------
    # 1. êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ë° ë§ˆì§€ë§‰ ë‚ ì§œ í™•ì¸
    # -------------------------------------------------------
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_name(KEY_PATH, scope)
    client = gspread.authorize(creds)
    
    try:
        doc = client.open_by_url(SHEET_URL)
        worksheet = doc.worksheet(sheet_name)
    except Exception as e:
        print(f"âš ï¸ ì‹œíŠ¸ ì ‘ì† ì‹¤íŒ¨ ({sheet_name}): {e}")
        return

    print(f"ğŸ§ [{category_name}] ì‹œíŠ¸ì˜ ë§ˆì§€ë§‰ ë°ì´í„°ë¥¼ í™•ì¸í•˜ëŠ” ì¤‘... (íƒ­ ì´ë¦„: {sheet_name})")
    
    date_values = worksheet.col_values(1)
    
    # í—¤ë”(1í–‰) ì œì™¸í•˜ê³  ë‚ ì§œë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    valid_dates = []
    for d in date_values[1:]:
        try:
            # 1. ë¹ˆ ê°’ì´ë‚˜ ê³µë°± ë¬¸ìì—´ì´ë©´ íŒ¨ìŠ¤
            if not d or str(d).strip() == '': continue
            
            # 2. ë‚ ì§œë¡œ ë³€í™˜ ì‹œë„
            ts = pd.to_datetime(d, errors='coerce') 
            
            # 3. [í•µì‹¬] ë³€í™˜ ê²°ê³¼ê°€ NaT(ë‚ ì§œ ì•„ë‹˜)ì´ë©´ íŒ¨ìŠ¤
            if pd.isna(ts):continue
            
            # 4. ì •ìƒ ë‚ ì§œë©´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            valid_dates.append(ts.date())
        except:
            continue # ë‚ ì§œ ì•„ë‹Œ ê°’(ë¹ˆì¹¸ ë“±)ì€ ë¬´ì‹œ

    if not valid_dates:
        print(f"âš ï¸ [{category_name}] ì‹œíŠ¸ì— ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 2024-01-01ë¶€í„° ê°€ì ¸ì˜µë‹ˆë‹¤.")
        target_start_date = '2024-01-01' # ê¸°ë³¸ ì‹œì‘ì¼ (ì ì ˆíˆ ìˆ˜ì •)
    else:
        last_date = max(valid_dates)
        # ë§ˆì§€ë§‰ ë‚ ì§œ + 1ì¼ (ë‹¤ìŒ ë‚ ë¶€í„° ê°€ì ¸ì˜¤ê¸° ìœ„í•¨)
        target_start_date = (last_date + timedelta(days=1)).strftime('%Y-%m-%d')
        print(f"ğŸ“… ì‹œíŠ¸ ë§ˆì§€ë§‰ ë‚ ì§œ: {last_date}")
        print(f"ğŸš€ ì—…ë°ì´íŠ¸ ì‹œì‘ì¼: {target_start_date} (ì´ ë‚ ì§œë¶€í„° ê°€ì ¸ì˜µë‹ˆë‹¤)")

    # -------------------------------------------------------
    # 2. BigQueryì—ì„œ ë°ì´í„° ì¡°íšŒ (Last Date + 1 ~ )
    # -------------------------------------------------------
    bq_client = bigquery.Client.from_service_account_json(KEY_PATH)
    
    # í•„ìš”í•œ ì›ë³¸ ì»¬ëŸ¼ë§Œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
    query = f"""
            SELECT 
                report_date, campaign_name, ad_name, ad_id, result_type, leads, spend
            FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}`
            WHERE report_date >= '{target_start_date}'
            ORDER BY report_date ASC, campaign_name ASC
        """
    
    print("â³ BigQuery ì¡°íšŒ ì¤‘...")
    df = bq_client.query(query).to_dataframe()
    if df.empty:
        print("âœ¨ ì—…ë°ì´íŠ¸í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ìµœì‹  ìƒíƒœ)")
        return

    # -------------------------------------------------------
    # 3. ë°ì´í„° ì¡°ë¦½ (ì¼ | ìº í˜ì¸ | ì†Œì¬ | ID | ê³µë€ | ê²°ê³¼ | CPA | ì§€ì¶œ)
    # -------------------------------------------------------
    df['report_date'] = df['report_date'].astype(str)
    df['leads'] = df['leads'].fillna(0).astype(int)
    df['spend'] = df['spend'].fillna(0).astype(int)
    
    def calc_cpa(row):
        if row['leads'] > 0:
            return int(round(row['spend'] / row['leads']))
        return 0
        
    df['cpa'] = df.apply(calc_cpa, axis=1)

    data_to_append = []
    
    # iterrowsë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í–‰ì„ ì§ì ‘ ì²˜ë¦¬
    for index, row in df.iterrows():
        # Leads ì²˜ë¦¬: 0ì´ë©´ ë¹ˆ ë¬¸ìì—´(""), ì•„ë‹ˆë©´ ìˆ«ì(int) ê·¸ëŒ€ë¡œ ì‚¬ìš©
        leads_val = int(row['leads'])
        leads_out = leads_val if leads_val > 0 else ""
        
        row_data = [
            str(row['report_date']),
            str(row['campaign_name']),
            str(row['ad_name']),
            str(row['ad_id']),
            str(row['result_type']),
            leads_out,          # ìˆ«ì ë˜ëŠ” ë¹ˆì¹¸
            int(row['cpa']),    # ìˆ«ì
            int(row['spend'])   # ìˆ«ì
        ]
        data_to_append.append(row_data)

    if data_to_append:
        print(f"ğŸ‘€ ì‹œíŠ¸ ì „ì†¡ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²«ì¤„): {data_to_append[0]}")
    else:
        print("âš ï¸ ì „ì†¡í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        return

    # -------------------------------------------------------
    # 4. ì‹œíŠ¸ì— ì¶”ê°€(ë¹ˆ í–‰ì„ ì°¾ì•„ì„œ Aì—´ë¶€í„° ê°•ì œë¡œ ì§‘ì–´ë„£ê¸°) 
    # -------------------------------------------------------
    # Aì—´(1ë²ˆì§¸ ì—´)ì˜ ë°ì´í„° ê°œìˆ˜ë¥¼ ì„¸ì„œ, ê·¸ ë‹¤ìŒ ì¤„ ë²ˆí˜¸ë¥¼ ì°¾ìŒ
    next_row = len(worksheet.col_values(1)) + 1
    end_row = next_row + len(data_to_append) - 1
    range_to_update = f"A{next_row}:H{end_row}"
    
    worksheet.update(
        range_name=range_to_update, 
        values=data_to_append, 
        value_input_option='USER_ENTERED'
    )
    
    print(f"âœ… [{category_name}] ì´ {len(data_to_append)}í–‰ ì¶”ê°€ ì™„ë£Œ! (ë²”ìœ„: {range_to_update})")

# -----------------------------------------------------------
# ì‹œíŠ¸ ì¤‘ë³µ ì œê±° í•¨ìˆ˜ (Config ì‚¬ìš©)
# -----------------------------------------------------------
def clean_sheet_duplicates(table_name):
    """
    ì‹œíŠ¸ì˜ ë°ì´í„°ë¥¼ ëª½ë•… ì½ì–´ì™€ì„œ [ì¼(Aì—´) + ê´‘ê³ ì†Œì¬ID(Dì—´)] ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µì„ ì œê±°í•˜ê³  ë‹¤ì‹œ ì”ë‹ˆë‹¤.
    """
    # ì‹œíŠ¸ íƒ­ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
    if 'beauty' in table_name:
        sheet_name = "Bë©”íƒ€"
        category_name = "ë·°í‹°"
    elif 'foot' in table_name:
        sheet_name = "Fë©”íƒ€"
        category_name = "í’‹"
    elif 'dosu' in table_name:
        sheet_name = "Dë©”íƒ€"
        category_name = "ë„ìˆ˜"
    else:
        return

    try:
        print(f"ğŸ§¹ [{category_name}] ì‹œíŠ¸ ìì²´ ì¤‘ë³µ ì œê±° ì‹œì‘...")
        
        # 1. ì¸ì¦ ë° ì‹œíŠ¸ ì—´ê¸°
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_name(KEY_PATH, scope)
        client = gspread.authorize(creds)
        doc = client.open_by_url(SHEET_URL)
        worksheet = doc.worksheet(sheet_name)

        # 2. ëª¨ë“  ë°ì´í„° ì½ê¸°
        all_values = worksheet.get_all_values()
        if not all_values:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        header = all_values[0] # í—¤ë”
        data = all_values[1:]  # ë³¸ë¬¸
        if not data: return
        
        initial_count = len(data)
        # 3. Pandasë¡œ ë³€í™˜í•˜ì—¬ ì¤‘ë³µ ì œê±°
        df = pd.DataFrame(data, columns=header)
        df_clean = df.drop_duplicates() 
        final_count = len(df_clean)

        if initial_count == final_count:
            print(f"âœ¨ [{category_name}] ì¤‘ë³µëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë³€ë™ ì—†ìŒ)")
            return

        # 4. ì‹œíŠ¸ í´ë¦¬ì–´ í›„ ë‹¤ì‹œ ì“°ê¸°
        print(f"ğŸ—‘ï¸ ì¤‘ë³µ {initial_count - final_count}ê±´ ë°œê²¬! ì•ˆì „í•˜ê²Œ ë®ì–´ì“°ê¸°ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")
        
        clean_data_list = df_clean.values.tolist()
        range_to_update = f"A2"
        worksheet.update(
            range_name=range_to_update, 
            values=clean_data_list,
            value_input_option='USER_ENTERED'
        )

        if initial_count > final_count:
            # ì§€ì›Œì•¼ í•  ì‹œì‘ í–‰ ë²ˆí˜¸ (í—¤ë” 1ì¤„ + ë°ì´í„° ê¸¸ì´ + 1)
            start_row_to_clear = final_count + 2 
            # ë„‰ë„‰í•˜ê²Œ ë§¨ ëê¹Œì§€ ì§€ìš°ê¸°
            worksheet.batch_clear([f"A{start_row_to_clear}:H{initial_count + 5}"])
            
        print(f"âœ… [{sheet_name}] ì •ë¦¬ ì™„ë£Œ!")

    except Exception as e:
        print(f"âŒ ì‹œíŠ¸ ì²­ì†Œ ì‹¤íŒ¨: {e}")


#========================================================
if __name__ == "__main__":

    MODE = "DAILY"   # ë§¤ì¼ ì•„ì¹¨ ìë™ ì‹¤í–‰ìš© (ì–´ì œ ë°ì´í„°)
    # MODE = "RANGE"   # ê³¼ê±° ë°ì´í„° í•œêº¼ë²ˆì— ìˆ˜ì§‘ìš© (ê¸°ê°„ ì§€ì •)

    # RANGE ëª¨ë“œì¼ ë•Œë§Œ ì‚¬ìš©í•˜ëŠ” ë‚ ì§œ (YYYYMMDD)
    START_DATE = "20250101"
    END_DATE = "20251221"
    print("=== ë©”íƒ€(Meta) ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ë° êµ¬ê¸€ ì‹œíŠ¸ ë™ê¸°í™” ===")


    for account in CONFIG['ad_accounts']:
        print(f"=== [{account['name']}] ì‘ì—… ì‹œì‘ ===")

        # 1. ìˆ˜ì§‘ (ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì‹¤í–‰)
        if MODE == "DAILY":
            link_meta_daily(account)
        elif MODE == "RANGE":
            link_meta_yearly(account, START_DATE, END_DATE)

        # 2. ì ì¬ í›„ì²˜ë¦¬ (ì¤‘ë³µì œê±°, ì‹œíŠ¸ì—°ë™)
        remove_duplicates(account['bq_table_name'])
        sync_bq_to_sheet(account['bq_table_name'])
        clean_sheet_duplicates(account['bq_table_name'])
        
        print("---------------------------------------")

    print("=== ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ===")
    
